{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import cartpole_swingup_envs\n",
    "from pilco.models import PILCO\n",
    "from pilco.controllers import RbfController\n",
    "from pilco.rewards import ExponentialReward\n",
    "import tensorflow as tf\n",
    "from gpflow import set_trainable\n",
    "import os\n",
    "import random\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "from utils import rollout\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')  # disable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBS = 5  # subsampling rate\n",
    "bf = 30  # the number of basis functions used\n",
    "maxiter=50  # max iteration for model and policy optimization\n",
    "max_action=1.0  # the maximum possible value that action can take\n",
    "\n",
    "# Hyper-parameters of the reward function (this is tricky to tune!)\n",
    "target = np.array([0.0, 0.05, 1.0, 0.0, 0.05])\n",
    "weights = np.diag([0.1, 0.1, 2.0, 2.0, 0.1])\n",
    "\n",
    "# Initial parameters of the GP model of the environment\n",
    "m_init = np.reshape([0.0, 0.0, -1.0, 0.0, 0.0], (1,5))\n",
    "S_init = np.diag([0.05, 0.05, 0.01, 0.01, 0.01])\n",
    "\n",
    "T = 30  # the number of timesteps fin each random rollout\n",
    "T_sim = T  # the number of timesteps in each rollout that uses the controller \n",
    "J = 3  # the number of random rollouts at the beginning before first optimization starts\n",
    "N = 3  # the number of rollouts after first optimization (at this stage optimization is performed after each rollout)\n",
    "restarts = 1 # the number of times that optimizations with different initializations are performed at each optimization step\n",
    "\n",
    "env = gym.make('CartPoleSwingUpContinuous-v0')\n",
    "env.seed(SEED)\n",
    "env.action_space.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** ITERATION no 0  ****\n",
      "-----Learned models------\n",
      "---Lengthscales---\n",
      "      GP0     GP1     GP2     GP3     GP4\n",
      "0   9.061  20.415  19.779  20.803  16.700\n",
      "1   5.068  28.888  27.052  28.498  31.804\n",
      "2   9.489   2.011   1.542   1.512   0.959\n",
      "3   6.832   1.141   1.595   1.555   0.937\n",
      "4  23.695  10.559  12.838  12.741   9.860\n",
      "5   5.529   3.291   7.768   5.762   2.586\n",
      "---Variances---\n",
      "     GP0    GP1    GP2    GP3     GP4\n",
      "0  0.041  3.671  0.526  0.597  10.557\n",
      "---Noises---\n",
      "     GP0    GP1    GP2    GP3    GP4\n",
      "0  0.001  0.001  0.001  0.001  0.001\n",
      "Controller's optimization: done in 22.2 seconds with reward=8.688.\n",
      "Action:  tf.Tensor([-0.66329072], shape=(1,), dtype=float64)\n",
      "State :  [-0.00882108 -1.19272496 -0.99932438 -0.03675294  2.48525259]\n",
      "Return so far:  0.0018514836498690827\n",
      "Action:  tf.Tensor([-0.47527033], shape=(1,), dtype=float64)\n",
      "State :  [-0.15464003 -1.79765776 -0.94190753 -0.33587231  3.61590899]\n",
      "Return so far:  0.06653912689266052\n",
      "Action:  tf.Tensor([0.11311082], shape=(1,), dtype=float64)\n",
      "State :  [-0.31549152 -1.33203587 -0.81287451 -0.58243886  1.47118303]\n",
      "Return so far:  0.4062094229399578\n",
      "Action:  tf.Tensor([0.20380271], shape=(1,), dtype=float64)\n",
      "State :  [-0.42748563 -0.81021408 -0.78543896 -0.61893913 -1.06475661]\n",
      "Return so far:  0.9284849732879822\n",
      "Action:  tf.Tensor([0.18819872], shape=(1,), dtype=float64)\n",
      "State :  [-0.48767911 -0.26784118 -0.89584657 -0.44436351 -3.5748289 ]\n",
      "Return so far:  1.3015025789123988\n",
      "Action:  tf.Tensor([0.28126278], shape=(1,), dtype=float64)\n",
      "State :  [-4.85043740e-01  4.31354898e-01 -9.99998709e-01  1.60705321e-03\n",
      " -5.94026474e+00]\n",
      "Return so far:  1.3726433438179497\n",
      "Action:  tf.Tensor([0.39760913], shape=(1,), dtype=float64)\n",
      "State :  [-0.42444134  0.69129644 -0.8097557   0.58676717 -5.99240965]\n",
      "Return so far:  1.574018067196582\n",
      "Action:  tf.Tensor([0.57291924], shape=(1,), dtype=float64)\n",
      "State :  [-0.352236    0.77732253 -0.39389017  0.91915751 -4.29702672]\n",
      "Return so far:  2.630095441641465\n",
      "Action:  tf.Tensor([0.78485175], shape=(1,), dtype=float64)\n",
      "State :  [-0.25586774  1.29755843 -0.05364503  0.99856007 -2.22871345]\n",
      "Return so far:  4.650793350277829\n",
      "Action:  tf.Tensor([0.49264607], shape=(1,), dtype=float64)\n",
      "State :  [-0.10911859  1.75105516  0.07147315  0.99744252  0.24639821]\n",
      "Return so far:  7.236449000748026\n",
      "Action:  tf.Tensor([-0.05208374], shape=(1,), dtype=float64)\n",
      "State :  [ 0.06364441  1.66753776 -0.05075107  0.99871133  2.69202447]\n",
      "Return so far:  9.779337098223422\n",
      "Action:  tf.Tensor([-0.53235067], shape=(1,), dtype=float64)\n",
      "State :  [ 0.20042985  0.82980546 -0.41328426  0.91060207  5.49776171]\n",
      "Return so far:  11.645613747024274\n",
      "Action:  tf.Tensor([-0.64296926], shape=(1,), dtype=float64)\n",
      "State :  [ 0.22504483 -0.80937816 -0.9069299   0.42128157  9.98926013]\n",
      "Return so far:  12.35447911945902\n",
      "Action:  tf.Tensor([-0.07753081], shape=(1,), dtype=float64)\n",
      "State :  [ 0.11546126 -0.89276899 -0.79463994 -0.60708102 10.21639402]\n",
      "Return so far:  12.527004702531107\n",
      "Action:  tf.Tensor([-0.08736142], shape=(1,), dtype=float64)\n",
      "State :  [ 0.07675374  0.21325385 -0.05315893 -0.99858606  6.68115509]\n",
      "Return so far:  14.14717905251937\n",
      "Action:  tf.Tensor([-0.47392149], shape=(1,), dtype=float64)\n",
      "State :  [ 0.10085294  0.14667342  0.4938787  -0.86953081  4.19580389]\n",
      "Return so far:  17.39105593690385\n",
      "Action:  tf.Tensor([-0.06733676], shape=(1,), dtype=float64)\n",
      "State :  [ 0.11282256  0.02051191  0.75188018 -0.65929978  2.06645151]\n",
      "Return so far:  21.548885669676004\n",
      "Action:  tf.Tensor([0.69703767], shape=(1,), dtype=float64)\n",
      "State :  [ 0.1435798   0.75241247  0.86829544 -0.49604741  2.07279038]\n",
      "Return so far:  26.095090934058902\n",
      "Action:  tf.Tensor([0.13323849], shape=(1,), dtype=float64)\n",
      "State :  [ 0.21879109  0.75451608  0.9369005  -0.34959614  1.02101854]\n",
      "Return so far:  30.84564148645288\n",
      "Action:  tf.Tensor([0.40387033], shape=(1,), dtype=float64)\n",
      "State :  [ 0.31144116  1.19615775  0.9696831  -0.24436588  1.3104705 ]\n",
      "Return so far:  35.66038991106514\n",
      "Action:  tf.Tensor([-0.00776097], shape=(1,), dtype=float64)\n",
      "State :  [ 0.42520316  1.05840628  0.98850729 -0.15117319  0.48123707]\n",
      "Return so far:  40.46364724303481\n",
      "Action:  tf.Tensor([0.23220639], shape=(1,), dtype=float64)\n",
      "State :  [ 0.54181305  1.33385729  0.99587765 -0.09070671  0.84552629]\n",
      "Return so far:  45.18757524886773\n",
      "Action:  tf.Tensor([-0.04956594], shape=(1,), dtype=float64)\n",
      "State :  [ 0.66949145  1.19902494  0.99961163 -0.02786749  0.35817386]\n",
      "Return so far:  49.77780930558033\n",
      "Action:  tf.Tensor([0.03882856], shape=(1,), dtype=float64)\n",
      "State :  [0.79062249 1.2338854  0.99995964 0.00898426 0.41230197]\n",
      "Return so far:  54.19855589168305\n",
      "Action:  tf.Tensor([-0.06245988], shape=(1,), dtype=float64)\n",
      "State :  [0.90963101 1.12873242 0.9991634  0.04089625 0.20717235]\n",
      "Return so far:  58.420134510918544\n",
      "Action:  tf.Tensor([-0.06999504], shape=(1,), dtype=float64)\n",
      "State :  [1.01837195 1.02766242 0.99844941 0.05566668 0.0724547 ]\n",
      "Return so far:  62.431415950286535\n",
      "Action:  tf.Tensor([-0.08603522], shape=(1,), dtype=float64)\n",
      "State :  [ 1.11633497  0.90824711  0.99840269  0.05649847 -0.08501705]\n",
      "Return so far:  66.23371517680062\n",
      "Action:  tf.Tensor([-0.08210603], shape=(1,), dtype=float64)\n",
      "State :  [ 1.20262832  0.79379201  0.99911524  0.04205626 -0.24324716]\n",
      "Return so far:  69.83755942230079\n",
      "Action:  tf.Tensor([-0.06053955], shape=(1,), dtype=float64)\n",
      "State :  [ 1.2785071   0.70326553  0.99992025  0.0126291  -0.39238656]\n",
      "Return so far:  73.25727002777641\n",
      "Action:  tf.Tensor([-0.02103302], shape=(1,), dtype=float64)\n",
      "State :  [ 1.34715143  0.65648448  0.99953921 -0.0303539  -0.5183894 ]\n",
      "Return so far:  76.50388661268443\n",
      "Total  [26.73702697]  Predicted:  tf.Tensor([[10.19853807]], shape=(1, 1), dtype=float64)\n",
      "**** ITERATION no 1  ****\n",
      "-----Learned models------\n",
      "---Lengthscales---\n",
      "      GP0     GP1     GP2     GP3     GP4\n",
      "0  11.450  28.201  22.416  24.396  27.380\n",
      "1   5.591  37.937  29.635  31.276  42.188\n",
      "2   8.781   1.676   1.518   1.543   0.982\n",
      "3   3.885   1.173   1.585   1.549   0.966\n",
      "4  17.787  10.729  13.047  13.425   9.412\n",
      "5   6.507   3.238   6.983   6.116   2.635\n",
      "---Variances---\n",
      "     GP0    GP1    GP2    GP3     GP4\n",
      "0  0.049  3.631  0.511  0.657  10.951\n",
      "---Noises---\n",
      "     GP0    GP1    GP2    GP3    GP4\n",
      "0  0.001  0.001  0.001  0.001  0.001\n",
      "Controller's optimization: done in 15.3 seconds with reward=10.199.\n",
      "Action:  tf.Tensor([-0.86291786], shape=(1,), dtype=float64)\n",
      "State :  [ 0.05027816 -1.37120881 -0.99634186 -0.085457    3.56647606]\n",
      "Return so far:  0.0035813470573686683\n",
      "Action:  tf.Tensor([-0.49398576], shape=(1,), dtype=float64)\n",
      "State :  [-0.11108128 -1.89055051 -0.88401631 -0.46745605  4.25152704]\n",
      "Return so far:  0.14554516884583435\n",
      "Action:  tf.Tensor([0.24362424], shape=(1,), dtype=float64)\n",
      "State :  [-0.27100884 -1.20474303 -0.69841598 -0.71569206  1.42100558]\n",
      "Return so far:  0.726717453920229\n",
      "Action:  tf.Tensor([0.39747901], shape=(1,), dtype=float64)\n",
      "State :  [-0.36226984 -0.48301536 -0.68361778 -0.72984021 -1.608388  ]\n",
      "Return so far:  1.5279155625846053\n",
      "Action:  tf.Tensor([0.37334266], shape=(1,), dtype=float64)\n",
      "State :  [-0.38020382  0.32795418 -0.86068067 -0.50914516 -4.75657973]\n",
      "Return so far:  2.0634582549059863\n",
      "Action:  tf.Tensor([0.23275217], shape=(1,), dtype=float64)\n",
      "State :  [-0.31652201  1.03222789 -0.99864379  0.05206327 -7.16046129]\n",
      "Return so far:  2.149578630580359\n",
      "Action:  tf.Tensor([0.11667311], shape=(1,), dtype=float64)\n",
      "State :  [-0.21923648  0.7312177  -0.74145319  0.67100459 -5.70407275]\n",
      "Return so far:  2.4597255658537995\n",
      "Action:  tf.Tensor([0.21450152], shape=(1,), dtype=float64)\n",
      "State :  [-0.15932821  0.46328968 -0.35237991  0.93585704 -3.32093007]\n",
      "Return so far:  3.695653279902632\n",
      "Action:  tf.Tensor([0.46534078], shape=(1,), dtype=float64)\n",
      "State :  [-0.10325979  0.75157154 -0.11461569  0.99340991 -1.1080545 ]\n",
      "Return so far:  5.704186356792029\n",
      "Action:  tf.Tensor([0.46956986], shape=(1,), dtype=float64)\n",
      "State :  [-0.01139363  1.17353388 -0.09758842  0.99522686  1.24329248]\n",
      "Return so far:  7.988311721391442\n",
      "Action:  tf.Tensor([0.34574959], shape=(1,), dtype=float64)\n",
      "State :  [ 0.1156236   1.37185124 -0.31122381  0.95033665  3.58706654]\n",
      "Return so far:  9.965943929387132\n",
      "Action:  tf.Tensor([0.21644526], shape=(1,), dtype=float64)\n",
      "State :  [ 0.24613598  1.12933845 -0.69794617  0.71615022  6.05547214]\n",
      "Return so far:  11.119406654936897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  tf.Tensor([-0.10474307], shape=(1,), dtype=float64)\n",
      "State :  [ 0.32304913  0.26070491 -0.99807788  0.06197208  9.09932165]\n",
      "Return so far:  11.350941199908801\n",
      "Action:  tf.Tensor([-0.64949349], shape=(1,), dtype=float64)\n",
      "State :  [ 0.32203006  0.0337374  -0.6186951  -0.78563119  9.00433385]\n",
      "Return so far:  11.747303267371224\n",
      "Action:  tf.Tensor([-0.80961819], shape=(1,), dtype=float64)\n",
      "State :  [ 0.33741777  0.21852199  0.13228333 -0.99121194  6.50921718]\n",
      "Return so far:  13.792863225243845\n",
      "Action:  tf.Tensor([-0.45523654], shape=(1,), dtype=float64)\n",
      "State :  [ 0.35847584  0.06261262  0.63436309 -0.77303524  4.04083155]\n",
      "Return so far:  17.348822196395965\n",
      "Action:  tf.Tensor([0.16835374], shape=(1,), dtype=float64)\n",
      "State :  [ 0.37145721  0.2009075   0.85833914 -0.51308277  2.65260461]\n",
      "Return so far:  21.680469080565416\n",
      "Action:  tf.Tensor([0.11568035], shape=(1,), dtype=float64)\n",
      "State :  [ 0.39176796  0.20841503  0.9495399  -0.31364627  1.62138993]\n",
      "Return so far:  26.33023584147895\n",
      "Action:  tf.Tensor([0.05181178], shape=(1,), dtype=float64)\n",
      "State :  [ 0.41010047  0.15512504  0.98184961 -0.18966114  0.85931877]\n",
      "Return so far:  31.089007937449974\n",
      "Action:  tf.Tensor([0.08582291], shape=(1,), dtype=float64)\n",
      "State :  [ 0.42705695  0.19895404  0.99300298 -0.11808927  0.57804759]\n",
      "Return so far:  35.87563039203391\n",
      "Action:  tf.Tensor([0.03198453], shape=(1,), dtype=float64)\n",
      "State :  [ 0.44639389  0.19040132  0.99737445 -0.07241694  0.31713165]\n",
      "Return so far:  40.661275736022404\n",
      "Action:  tf.Tensor([0.04298355], shape=(1,), dtype=float64)\n",
      "State :  [ 0.46650333  0.22036287  0.99900504 -0.04459733  0.24308528]\n",
      "Return so far:  45.43436135774985\n",
      "Action:  tf.Tensor([0.01042355], shape=(1,), dtype=float64)\n",
      "State :  [ 0.48812717  0.21246072  0.9996809  -0.0252607   0.13510765]\n",
      "Return so far:  50.18880619885585\n",
      "Action:  tf.Tensor([0.01626072], shape=(1,), dtype=float64)\n",
      "State :  [ 0.50974366  0.22315014  0.99991485 -0.01304971  0.11234002]\n",
      "Return so far:  54.92196280551228\n",
      "Action:  tf.Tensor([-0.00112984], shape=(1,), dtype=float64)\n",
      "State :  [ 0.53158773  0.21252446  0.99999173 -0.00406656  0.06358652]\n",
      "Return so far:  59.631844086374805\n",
      "Action:  tf.Tensor([0.00173428], shape=(1,), dtype=float64)\n",
      "State :  [0.55274886 0.21094532 0.9999984  0.00178608 0.05560376]\n",
      "Return so far:  64.31787279721098\n",
      "Action:  tf.Tensor([-0.0074586], shape=(1,), dtype=float64)\n",
      "State :  [0.57329969 0.19794918 0.99998037 0.00626579 0.0323879 ]\n",
      "Return so far:  68.97960631720562\n",
      "Action:  tf.Tensor([-0.00622932], shape=(1,), dtype=float64)\n",
      "State :  [0.592733   0.18929539 0.99995696 0.00927789 0.02918093]\n",
      "Return so far:  73.61742206953382\n",
      "Action:  tf.Tensor([-0.01122615], shape=(1,), dtype=float64)\n",
      "State :  [0.61105658 0.17448652 0.99993218 0.01164637 0.01751179]\n",
      "Return so far:  78.23182642205404\n",
      "Action:  tf.Tensor([-0.01078142], shape=(1,), dtype=float64)\n",
      "State :  [0.62798778 0.16178544 0.9999118  0.01328117 0.01600176]\n",
      "Return so far:  82.82387239662297\n",
      "Total  [29.35370691]  Predicted:  tf.Tensor([[10.7690712]], shape=(1, 1), dtype=float64)\n",
      "**** ITERATION no 2  ****\n",
      "-----Learned models------\n",
      "---Lengthscales---\n",
      "      GP0     GP1     GP2     GP3     GP4\n",
      "0  12.084  28.230  23.163  24.752  27.482\n",
      "1   5.714  41.603  31.571  33.852  43.670\n",
      "2   8.002   1.816   1.526   1.537   0.993\n",
      "3   3.586   1.090   1.579   1.553   0.940\n",
      "4  17.766  10.393  13.139  13.468   9.260\n",
      "5   6.770   3.294   6.891   6.174   2.667\n",
      "---Variances---\n",
      "     GP0    GP1   GP2    GP3    GP4\n",
      "0  0.051  3.458  0.51  0.653  10.77\n",
      "---Noises---\n",
      "     GP0    GP1    GP2    GP3    GP4\n",
      "0  0.001  0.001  0.001  0.001  0.001\n",
      "Controller's optimization: done in 15.1 seconds with reward=10.770.\n",
      "Action:  tf.Tensor([-0.76227343], shape=(1,), dtype=float64)\n",
      "State :  [-0.17134791 -1.58113472 -0.99465663  0.10323852  3.90030829]\n",
      "Return so far:  0.054020381328906034\n",
      "Action:  tf.Tensor([-0.05311387], shape=(1,), dtype=float64)\n",
      "State :  [-0.33271957 -1.58693365 -0.9561873  -0.29275561  3.77932664]\n",
      "Return so far:  0.09252959524204746\n",
      "Action:  tf.Tensor([0.30920055], shape=(1,), dtype=float64)\n",
      "State :  [-0.46165999 -0.85705159 -0.84160083 -0.54010003  1.10868259]\n",
      "Return so far:  0.3721196340572609\n",
      "Action:  tf.Tensor([0.46481302], shape=(1,), dtype=float64)\n",
      "State :  [-0.51241365  0.01608665 -0.850265   -0.52635485 -2.07048102]\n",
      "Return so far:  0.7677442231533946\n",
      "Action:  tf.Tensor([0.52683128], shape=(1,), dtype=float64)\n",
      "State :  [-0.469542    1.0770019  -0.97812803 -0.20800373 -5.51057648]\n",
      "Return so far:  0.9450777099954734\n",
      "Action:  tf.Tensor([0.11245138], shape=(1,), dtype=float64)\n",
      "State :  [-0.35057115  1.20054492 -0.92914565  0.36971388 -5.76702222]\n",
      "Return so far:  1.002724473753449\n",
      "Action:  tf.Tensor([0.14130545], shape=(1,), dtype=float64)\n",
      "State :  [-0.24294652  0.88394385 -0.6353616   0.77221476 -3.7579117 ]\n",
      "Return so far:  1.5935599414402177\n",
      "Action:  tf.Tensor([0.32771835], shape=(1,), dtype=float64)\n",
      "State :  [-0.15421886  0.93085185 -0.38232694  0.92402712 -1.72948215]\n",
      "Return so far:  2.900389177675772\n",
      "Action:  tf.Tensor([0.42913072], shape=(1,), dtype=float64)\n",
      "State :  [-0.04976944  1.23018712 -0.2966407   0.95498916  0.33695401]\n",
      "Return so far:  4.607882485383345\n",
      "Action:  tf.Tensor([0.31145208], shape=(1,), dtype=float64)\n",
      "State :  [ 0.08070536  1.39556102 -0.41013679  0.91202402  2.52404363]\n",
      "Return so far:  6.235443269129392\n",
      "Action:  tf.Tensor([0.20222049], shape=(1,), dtype=float64)\n",
      "State :  [ 0.21671585  1.25419243 -0.69354537  0.72041295  4.81466652]\n",
      "Return so far:  7.304001099443291\n",
      "Action:  tf.Tensor([-0.08120009], shape=(1,), dtype=float64)\n",
      "State :  [ 0.3141359   0.53782141 -0.9787749   0.20493828  7.63574505]\n",
      "Return so far:  7.604457737570981\n",
      "Action:  tf.Tensor([-0.86764225], shape=(1,), dtype=float64)\n",
      "State :  [ 0.31119224 -0.42453017 -0.76393036 -0.64529869  9.69195201]\n",
      "Return so far:  7.807369609185983\n",
      "Action:  tf.Tensor([-0.67559033], shape=(1,), dtype=float64)\n",
      "State :  [ 0.28974366  0.01777554 -0.0082767  -0.99996575  7.02831909]\n",
      "Return so far:  9.4865861670657\n",
      "Action:  tf.Tensor([-0.43022464], shape=(1,), dtype=float64)\n",
      "State :  [ 0.29796026  0.03439229  0.56304856 -0.82642381  4.61210011]\n",
      "Return so far:  12.826456002183475\n",
      "Action:  tf.Tensor([0.04445134], shape=(1,), dtype=float64)\n",
      "State :  [ 0.3050421   0.07388871  0.83546323 -0.54954634  2.91131719]\n",
      "Return so far:  17.103570465440445\n",
      "Action:  tf.Tensor([0.06277238], shape=(1,), dtype=float64)\n",
      "State :  [ 0.31001738  0.00945743  0.94100975 -0.33837945  1.64450784]\n",
      "Return so far:  21.775257420537603\n",
      "Action:  tf.Tensor([0.07443929], shape=(1,), dtype=float64)\n",
      "State :  [ 0.30955783 -0.01668289  0.97710319 -0.21276598  0.88896605]\n",
      "Return so far:  26.5887616466335\n",
      "Action:  tf.Tensor([0.10152905], shape=(1,), dtype=float64)\n",
      "State :  [ 0.30994177  0.04236572  0.99025291 -0.13928094  0.59015144]\n",
      "Return so far:  31.45207265407096\n",
      "Action:  tf.Tensor([0.05703385], shape=(1,), dtype=float64)\n",
      "State :  [ 0.31483364  0.06422885  0.9958001  -0.09155414  0.35428156]\n",
      "Return so far:  36.333010482963175\n",
      "Action:  tf.Tensor([0.04898651], shape=(1,), dtype=float64)\n",
      "State :  [ 0.32235974  0.0952774   0.99808884 -0.06179538  0.2385964 ]\n",
      "Return so far:  41.21779542844457\n",
      "Action:  tf.Tensor([0.03064684], shape=(1,), dtype=float64)\n",
      "State :  [ 0.33244035  0.11143574  0.9991089  -0.04220666  0.14837544]\n",
      "Return so far:  46.099814394381944\n",
      "Action:  tf.Tensor([0.02528273], shape=(1,), dtype=float64)\n",
      "State :  [ 0.3442017   0.12834967  0.99955884 -0.02970064  0.10032975]\n",
      "Return so far:  50.975523239384025\n",
      "Action:  tf.Tensor([0.01812564], shape=(1,), dtype=float64)\n",
      "State :  [ 0.35745861  0.13988473  0.99977217 -0.02134496  0.0651989 ]\n",
      "Return so far:  55.842622878980464\n",
      "Action:  tf.Tensor([0.01510742], shape=(1,), dtype=float64)\n",
      "State :  [ 0.37184961  0.15059007  0.99987528 -0.01579348  0.04543593]\n",
      "Return so far:  60.69943684311869\n",
      "Action:  tf.Tensor([0.0119865], shape=(1,), dtype=float64)\n",
      "State :  [ 0.38722669  0.15898703  0.99992895 -0.01192067  0.03175341]\n",
      "Return so far:  65.54453942062077\n",
      "Action:  tf.Tensor([0.01017284], shape=(1,), dtype=float64)\n",
      "State :  [ 0.40340728  0.16634618  0.99995812 -0.00915142  0.0237812 ]\n",
      "Return so far:  70.37665536069088\n",
      "Action:  tf.Tensor([0.0084721], shape=(1,), dtype=float64)\n",
      "State :  [ 0.42027206  0.17233479  0.99997514 -0.00705157  0.01846725]\n",
      "Return so far:  75.19458196687302\n",
      "Action:  tf.Tensor([0.00719033], shape=(1,), dtype=float64)\n",
      "State :  [ 0.43769708  0.17730756  0.99998551 -0.00538333  0.01529996]\n",
      "Return so far:  79.99717757904237\n",
      "Action:  tf.Tensor([0.0059854], shape=(1,), dtype=float64)\n",
      "State :  [ 0.4555771   0.18119462  0.99999208 -0.00397957  0.01323085]\n",
      "Return so far:  84.78335071438751\n",
      "Total  [29.62361972]  Predicted:  tf.Tensor([[11.10888432]], shape=(1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Initial random rollouts to generate a dataset\n",
    "X, Y, _, _ = rollout(env, None, timesteps=T, random=True, SUBS=SUBS, verbose=False, render=True)\n",
    "for i in range(1,J):\n",
    "    X_, Y_, _, _ = rollout(env, None, timesteps=T, random=True, SUBS=SUBS, verbose=False, render=True)\n",
    "    X = np.vstack((X, X_))\n",
    "    Y = np.vstack((Y, Y_))\n",
    "\n",
    "state_dim = Y.shape[1]\n",
    "control_dim = X.shape[1] - state_dim\n",
    "\n",
    "controller = RbfController(state_dim=state_dim, control_dim=control_dim, num_basis_functions=bf, max_action=max_action)\n",
    "R = ExponentialReward(state_dim=state_dim, t=target, W=weights)\n",
    "\n",
    "pilco = PILCO((X, Y), controller=controller, horizon=T, reward=R, m_init=m_init, S_init=S_init)\n",
    "\n",
    "# fix the likelihood variance parameters of the GP models for numerical stability\n",
    "for model in pilco.mgpr.models:\n",
    "    model.likelihood.variance.assign(0.001) # 0.001\n",
    "    set_trainable(model.likelihood.variance, False)\n",
    "\n",
    "# policy and model optimization\n",
    "r_new = np.zeros((T, 1))\n",
    "for rollouts in range(N):\n",
    "    print(\"**** ITERATION no\", rollouts, \" ****\")\n",
    "    pilco.optimize_models(maxiter=maxiter, restarts=restarts)\n",
    "    pilco.optimize_policy(maxiter=maxiter, restarts=restarts)\n",
    "\n",
    "    is_render = False if rollouts == N-1 else True\n",
    "    X_new, Y_new, _, _ = rollout(env, pilco, timesteps=T_sim, verbose=True, SUBS=SUBS, render=is_render)\n",
    "\n",
    "    # Since we had decide on the various parameters of the reward function\n",
    "    # we might want to verify that it behaves as expected by inspection\n",
    "    for i in range(len(X_new)):\n",
    "        r_new[:, 0] = R.compute_reward(X_new[i,None,:-1], 0.001 * np.eye(state_dim))[0]\n",
    "    total_r = sum(r_new)\n",
    "    _, _, r = pilco.predict(X_new[0,None,:-1], 0.001 * S_init, T)\n",
    "    print(\"Total \", total_r, \" Predicted: \", r)\n",
    "\n",
    "    # Update dataset\n",
    "    X = np.vstack((X, X_new)); Y = np.vstack((Y, Y_new))\n",
    "    pilco.mgpr.set_data((X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for 1000 timesteps\n",
    "_ = rollout(env, pilco, timesteps=1000, verbose=False, SUBS=SUBS, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
